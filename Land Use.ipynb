{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852adf69",
   "metadata": {},
   "source": [
    "Merge area of mine polygons with mines (do this step before byproduct analysis)\n",
    "1) merge area based on cluster id and drop mines that have no area value --> about 63 mines \n",
    "2) sum up all polygon areas associated to a single mine\n",
    "3) about 30% of mine share an id cluster with atlease one other mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7aacd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from Data Input/Maus_Spa_Data/polygon_attribute_table_all.xlsx...\n",
      "Reading data from Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx...\n",
      "Processing mines and their associated areas...\n",
      "Removing rows with no area values...\n",
      "Removed 60 rows with no area values\n",
      "Saving results to Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx...\n",
      "Original number of mines: 598\n",
      "Final number of rows with area values: 11902\n",
      "Process completed successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def merge_area_data():\n",
    "    # Define file paths\n",
    "    input_file = \"Data Input/Maus_Spa_Data/polygon_attribute_table_all.xlsx\"\n",
    "    output_file = \"Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx\"\n",
    "    \n",
    "    # Read both Excel files\n",
    "    print(f\"Reading data from {input_file}...\")\n",
    "    area_df = pd.read_excel(input_file)\n",
    "    \n",
    "    print(f\"Reading data from {output_file}...\")\n",
    "    mines_df = pd.read_excel(output_file)\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    if 'id_cluster' not in area_df.columns or 'area_mine' not in area_df.columns:\n",
    "        raise ValueError(\"Missing required columns in input dataset\")\n",
    "    \n",
    "    if 'PROP_ID' not in mines_df.columns or 'id_cluster' not in mines_df.columns:\n",
    "        raise ValueError(\"Missing required columns in output dataset\")\n",
    "    \n",
    "    # Create a new dataframe to store the expanded results\n",
    "    result_rows = []\n",
    "    \n",
    "    # For each mine, create multiple rows if needed\n",
    "    print(\"Processing mines and their associated areas...\")\n",
    "    for _, mine_row in mines_df.iterrows():\n",
    "        mine_data = mine_row.to_dict()\n",
    "        cluster_id = mine_data['id_cluster']\n",
    "        \n",
    "        # Find all matching areas for this cluster_id\n",
    "        matching_areas = area_df[area_df['id_cluster'] == cluster_id]\n",
    "        \n",
    "        if len(matching_areas) > 0:\n",
    "            # Create a new row for each matching area\n",
    "            for _, area_row in matching_areas.iterrows():\n",
    "                new_row = mine_data.copy()\n",
    "                new_row['area_total'] = area_row['area_mine']\n",
    "                result_rows.append(new_row)\n",
    "        else:\n",
    "            # Add the mine with empty area_total\n",
    "            mine_data['area_total'] = np.nan\n",
    "            result_rows.append(mine_data)\n",
    "    \n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    result_df = pd.DataFrame(result_rows)\n",
    "    \n",
    "    # Remove rows with no area values\n",
    "    print(\"Removing rows with no area values...\")\n",
    "    result_df_filtered = result_df.dropna(subset=['area_total'])\n",
    "    \n",
    "    removed_count = len(result_df) - len(result_df_filtered)\n",
    "    print(f\"Removed {removed_count} rows with no area values\")\n",
    "    \n",
    "    # Save the result\n",
    "    output_path = \"Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx\"\n",
    "    print(f\"Saving results to {output_path}...\")\n",
    "    result_df_filtered.to_excel(output_path, index=False)\n",
    "    \n",
    "    # Print statistics\n",
    "    original_mines = len(mines_df)\n",
    "    final_rows = len(result_df_filtered)\n",
    "    print(f\"Original number of mines: {original_mines}\")\n",
    "    print(f\"Final number of rows with area values: {final_rows}\")\n",
    "    print(f\"Process completed successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        merge_area_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d241ed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx...\n",
      "Calculating total area for each mine...\n",
      "Saving results to Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx...\n",
      "Processed 11902 rows into 538 unique mines\n",
      "Process completed successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sum_areas_by_mine():\n",
    "    # Define file paths\n",
    "    input_file = \"Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx\"\n",
    "    \n",
    "    # Read the file with area data\n",
    "    print(f\"Reading data from {input_file}...\")\n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_cols = ['PROP_ID', 'area_total']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in input file: {', '.join(missing_cols)}\")\n",
    "    \n",
    "    # Group by PROP_ID and sum the area values\n",
    "    print(\"Calculating total area for each mine...\")\n",
    "    # Sum the areas for each mine (PROP_ID)\n",
    "    area_sums = df.groupby('PROP_ID')['area_total'].sum().reset_index()\n",
    "    \n",
    "    # Get one row per mine with all original columns (except area_total)\n",
    "    other_cols = [col for col in df.columns if col != 'area_total']\n",
    "    unique_mines = df[other_cols].drop_duplicates(subset=['PROP_ID'])\n",
    "    \n",
    "    # Merge the summed areas back to the unique mines\n",
    "    result_df = pd.merge(\n",
    "        unique_mines,\n",
    "        area_sums,\n",
    "        on='PROP_ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Save the result\n",
    "    output_path = \"Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx\"\n",
    "    print(f\"Saving results to {output_path}...\")\n",
    "    result_df.to_excel(output_path, index=False)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Processed {len(df)} rows into {len(result_df)} unique mines\")\n",
    "    print(\"Process completed successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        sum_areas_by_mine()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638dc32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx...\n",
      "Found 538 rows in the dataset\n",
      "\n",
      "Total number of unique mines (PROP_IDs): 538\n",
      "Total number of unique clusters: 459\n",
      "\n",
      "1. Mines sharing clusters with other mines:\n",
      "   Number of clusters shared by multiple mines: 44\n",
      "   Number of mines that share clusters with other mines: 123 (22.86% of all mines)\n",
      "\n",
      "2. Mines with multiple cluster assignments:\n",
      "   Number of mines assigned to multiple clusters: 0 (0.00% of all mines)\n",
      "\n",
      "3. Complex clustering patterns:\n",
      "   Mines that both have multiple clusters AND share clusters with other mines: 0 (0.00% of all mines)\n",
      "\n",
      "--- Summary ---\n",
      "Total mines: 538\n",
      "Total clusters: 459\n",
      "Mines with simple clustering (one cluster, not shared): 415 (77.14%)\n",
      "Mines sharing clusters with others (but having only one cluster): 123 (22.86%)\n",
      "Mines with multiple clusters (but not sharing with others): 0 (0.00%)\n",
      "Complex mines (multiple clusters AND sharing with others): 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_mine_clusters(excel_path):\n",
    "    \"\"\"\n",
    "    Analyze the clustering patterns of mines in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    excel_path : str\n",
    "        Path to the Excel file containing the final output data\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    print(f\"Reading data from {excel_path}...\")\n",
    "    df = pd.read_excel(excel_path)\n",
    "    print(f\"Found {len(df)} rows in the dataset\")\n",
    "    \n",
    "    # Verify required columns exist\n",
    "    if 'PROP_ID' not in df.columns:\n",
    "        raise ValueError(f\"Column 'PROP_ID' not found in the file. Available columns: {df.columns.tolist()}\")\n",
    "    if 'id_cluster' not in df.columns:\n",
    "        raise ValueError(f\"Column 'id_cluster' not found in the file. Available columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Ensure ID columns are strings\n",
    "    df['PROP_ID'] = df['PROP_ID'].astype(str)\n",
    "    df['id_cluster'] = df['id_cluster'].astype(str)\n",
    "    \n",
    "    # Count total unique mines\n",
    "    total_mines = df['PROP_ID'].nunique()\n",
    "    print(f\"\\nTotal number of unique mines (PROP_IDs): {total_mines}\")\n",
    "    \n",
    "    # Count total unique clusters\n",
    "    total_clusters = df['id_cluster'].nunique()\n",
    "    print(f\"Total number of unique clusters: {total_clusters}\")\n",
    "    \n",
    "    # 1. Find mines sharing clusters with other mines\n",
    "    # Group by cluster and count unique mines in each cluster\n",
    "    cluster_counts = df.groupby('id_cluster')['PROP_ID'].nunique().reset_index()\n",
    "    cluster_counts.columns = ['id_cluster', 'mine_count']\n",
    "    \n",
    "    # Clusters with more than one mine\n",
    "    shared_clusters = cluster_counts[cluster_counts['mine_count'] > 1]\n",
    "    \n",
    "    # Get unique mines in shared clusters\n",
    "    mines_in_shared_clusters = df[df['id_cluster'].isin(shared_clusters['id_cluster'])]['PROP_ID'].unique()\n",
    "    num_mines_sharing_clusters = len(mines_in_shared_clusters)\n",
    "    \n",
    "    print(f\"\\n1. Mines sharing clusters with other mines:\")\n",
    "    print(f\"   Number of clusters shared by multiple mines: {len(shared_clusters)}\")\n",
    "    print(f\"   Number of mines that share clusters with other mines: {num_mines_sharing_clusters} \"\n",
    "          f\"({(num_mines_sharing_clusters/total_mines)*100:.2f}% of all mines)\")\n",
    "    \n",
    "    # 2. Find mines with multiple clusters assigned\n",
    "    # Count clusters per mine\n",
    "    mine_cluster_counts = df.groupby('PROP_ID')['id_cluster'].nunique().reset_index()\n",
    "    mine_cluster_counts.columns = ['PROP_ID', 'cluster_count']\n",
    "    \n",
    "    # Mines with more than one cluster\n",
    "    multi_cluster_mines = mine_cluster_counts[mine_cluster_counts['cluster_count'] > 1]\n",
    "    num_multi_cluster_mines = len(multi_cluster_mines)\n",
    "    \n",
    "    print(f\"\\n2. Mines with multiple cluster assignments:\")\n",
    "    print(f\"   Number of mines assigned to multiple clusters: {num_multi_cluster_mines} \"\n",
    "          f\"({(num_multi_cluster_mines/total_mines)*100:.2f}% of all mines)\")\n",
    "    \n",
    "    if num_multi_cluster_mines > 0:\n",
    "        avg_clusters_per_mine = multi_cluster_mines['cluster_count'].mean()\n",
    "        max_clusters_per_mine = multi_cluster_mines['cluster_count'].max()\n",
    "        print(f\"   Average number of clusters per mine (for mines with multiple clusters): {avg_clusters_per_mine:.2f}\")\n",
    "        print(f\"   Maximum number of clusters assigned to a single mine: {max_clusters_per_mine}\")\n",
    "    \n",
    "    # 3. Find mines that both have multiple clusters AND share clusters with others\n",
    "    # Get list of mines with multiple clusters\n",
    "    multi_cluster_mine_ids = multi_cluster_mines['PROP_ID'].unique()\n",
    "    \n",
    "    # Check which of these also appear in the shared clusters list\n",
    "    complex_mines = np.intersect1d(multi_cluster_mine_ids, mines_in_shared_clusters)\n",
    "    num_complex_mines = len(complex_mines)\n",
    "    \n",
    "    print(f\"\\n3. Complex clustering patterns:\")\n",
    "    print(f\"   Mines that both have multiple clusters AND share clusters with other mines: {num_complex_mines} \"\n",
    "          f\"({(num_complex_mines/total_mines)*100:.2f}% of all mines)\")\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"\\n--- Summary ---\")\n",
    "    print(f\"Total mines: {total_mines}\")\n",
    "    print(f\"Total clusters: {total_clusters}\")\n",
    "    print(f\"Mines with simple clustering (one cluster, not shared): \"\n",
    "          f\"{total_mines - num_mines_sharing_clusters - num_multi_cluster_mines + num_complex_mines} \"\n",
    "          f\"({(total_mines - num_mines_sharing_clusters - num_multi_cluster_mines + num_complex_mines)/total_mines*100:.2f}%)\")\n",
    "    print(f\"Mines sharing clusters with others (but having only one cluster): \"\n",
    "          f\"{num_mines_sharing_clusters - num_complex_mines} \"\n",
    "          f\"({(num_mines_sharing_clusters - num_complex_mines)/total_mines*100:.2f}%)\")\n",
    "    print(f\"Mines with multiple clusters (but not sharing with others): \"\n",
    "          f\"{num_multi_cluster_mines - num_complex_mines} \"\n",
    "          f\"({(num_multi_cluster_mines - num_complex_mines)/total_mines*100:.2f}%)\")\n",
    "    print(f\"Complex mines (multiple clusters AND sharing with others): \"\n",
    "          f\"{num_complex_mines} ({(num_complex_mines/total_mines)*100:.2f}%)\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    excel_path = \"Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        analyze_mine_clusters(excel_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "213b31c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 538 rows to Data Input\\Byproduct\\Total_Rock.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "byproducts_path = Path(\"Data Input/Byproduct/Byproducts_CumProd_final.xlsx\")\n",
    "prod_path = Path(\"Data Output/Commodity Production/Commodity_Production-1980_2023_final.xlsx\")\n",
    "out_path = Path(\"Data Input/Byproduct/Total_Rock.xlsx\")  \n",
    "\n",
    "# Read inputs\n",
    "total_rock = pd.read_excel(byproducts_path, sheet_name=\"Total_Rock\")\n",
    "prod = pd.read_excel(prod_path)\n",
    "\n",
    "# Normalize column name just in case\n",
    "if \"PROP_ID\" not in total_rock.columns and \"Prop_id\" in total_rock.columns:\n",
    "    total_rock = total_rock.rename(columns={\"Prop_id\": \"PROP_ID\"})\n",
    "if \"PROP_ID\" not in prod.columns and \"Prop_id\" in prod.columns:\n",
    "    prod = prod.rename(columns={\"Prop_id\": \"PROP_ID\"})\n",
    "\n",
    "# Get the set of PROP_IDs from the second dataset\n",
    "prop_ids = prod[\"PROP_ID\"].dropna().astype(str).unique()\n",
    "\n",
    "# Filter Total_Rock by those PROP_IDs\n",
    "filtered = total_rock[total_rock[\"PROP_ID\"].astype(str).isin(prop_ids)]\n",
    "\n",
    "# Save output (keep the same sheet name)\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "    filtered.to_excel(writer, index=False, sheet_name=\"Total_Rock\")\n",
    "\n",
    "print(f\"Saved {len(filtered):,} rows to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c450f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup created: Data Output\\Commodity Production\\Commodity_Production-1980_2023_final-backup-20250911-204627.xlsx\n",
      "Updated file with 'area_allocated': Data Output\\Commodity Production\\Commodity_Production-1980_2023_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# --- Paths ---\n",
    "xlsx_path = Path(\"Data Output\") / \"Commodity Production\" / \"Commodity_Production-1980_2023_final.xlsx\"\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_excel(xlsx_path)\n",
    "\n",
    "# --- Required columns ---\n",
    "required = {\"PROP_ID\", \"id_cluster\", \"area_total\", \"Total Rock\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "# --- Coerce numerics (tolerant to strings/commas) ---\n",
    "df[\"area_total\"] = pd.to_numeric(df[\"area_total\"], errors=\"coerce\")\n",
    "df[\"Total Rock\"] = pd.to_numeric(df[\"Total Rock\"], errors=\"coerce\")\n",
    "\n",
    "# --- Cluster totals ---\n",
    "# If area_total is truly cluster-level, it should be the same across the cluster.\n",
    "# We'll take the first non-null per cluster to be safe.\n",
    "cluster_total_rock = df.groupby(\"id_cluster\")[\"Total Rock\"].transform(\"sum\")\n",
    "cluster_area_total = df.groupby(\"id_cluster\")[\"area_total\"].transform(\n",
    "    lambda s: s.dropna().iloc[0] if s.dropna().size else np.nan\n",
    ")\n",
    "\n",
    "# --- Compute allocation ---\n",
    "# Ratio = mine_total_rock / cluster_total_rock\n",
    "# Allocated area = Ratio * cluster_area_total\n",
    "# Guard against division by zero or missing totals.\n",
    "ratio = np.where(cluster_total_rock > 0, df[\"Total Rock\"] / cluster_total_rock, np.nan)\n",
    "df[\"area_allocated\"] = ratio * cluster_area_total\n",
    "\n",
    "# --- (Optional) sanity check: sums per cluster should match cluster area_total (within tolerance) ---\n",
    "# You can comment this out if you don't want console output.\n",
    "check = (\n",
    "    df.groupby(\"id_cluster\")\n",
    "      .agg(\n",
    "          area_total_first=(\"area_total\", lambda s: s.dropna().iloc[0] if s.dropna().size else np.nan),\n",
    "          area_allocated_sum=(\"area_allocated\", \"sum\")\n",
    "      )\n",
    ")\n",
    "mismatch = (check[\"area_total_first\"] - check[\"area_allocated_sum\"]).abs()\n",
    "bad = mismatch[mismatch > 1e-6]\n",
    "if not bad.empty:\n",
    "    print(\"Warning: for these clusters, allocated sum != area_total (>|1e-6|):\")\n",
    "    print(bad)\n",
    "\n",
    "# --- Backup and save ---\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "backup_path = xlsx_path.with_name(xlsx_path.stem + f\"-backup-{timestamp}\" + xlsx_path.suffix)\n",
    "try:\n",
    "    shutil.copy2(xlsx_path, backup_path)\n",
    "    print(f\"Backup created: {backup_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Backup skipped (non-fatal): {e}\")\n",
    "\n",
    "# Overwrite the original file with the new column\n",
    "df.to_excel(xlsx_path, index=False)\n",
    "print(f\"Updated file with 'area_allocated': {xlsx_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
